{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ random transforms\n",
    "+ thread-safe gens\n",
    "+ 128x128 images\n",
    "+ extra dense layer\n",
    "+ K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RUN = 'F'\n",
    "RND = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGES_DIR = '/d2/caches/kaggle-planet/processed-images-64x64/'\n",
    "IMAGE_SHAPE = (64, 64, 4)\n",
    "\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "TRAIN_EPOCHS = 1\n",
    "\n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "VAL_BATCH_SIZE = 8\n",
    "\n",
    "TENSORBOARD_DIR = '/tensorboard/planet/' + RUN\n",
    "MODEL_CHECKPOINT_DIR = '/d2/caches/kaggle-planet/models/' + RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_CHECKPOINT_DIR not defined \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run 'Lib.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "X_files = np.load('out/X_files.npy')[:1280]\n",
    "Y_tags_misc = np.load('out/Y_tags_misc.npy')[:1280]\n",
    "Y_tags_weather = np.load('out/Y_tags_weather.npy')[:1280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "X_files = np.load('out/X_files.npy')\n",
    "Y_tags_misc = np.load('out/Y_tags_misc.npy')\n",
    "Y_tags_weather = np.load('out/Y_tags_weather.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into tran/val sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_files_train, X_files_val, \\\n",
    "Y_tags_misc_train, Y_tags_misc_val, \\\n",
    "Y_tags_weather_train, Y_tags_weather_val = \\\n",
    "train_test_split(\n",
    "    X_files,\n",
    "    Y_tags_misc,\n",
    "    Y_tags_weather,\n",
    "    test_size=VAL_SPLIT,\n",
    "    random_state=RND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per epoch (train): 32376 of 32383\n"
     ]
    }
   ],
   "source": [
    "# calculate samples per epoch so that epoch can consist of integer number of batches\n",
    "TRAIN_SAMPLES_PER_EPOCH = int(len(X_files_train) / TRAIN_BATCH_SIZE) * TRAIN_BATCH_SIZE\n",
    "print ('Samples per epoch (train):', TRAIN_SAMPLES_PER_EPOCH, 'of', len(X_files_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per epoch (val): 8096 of 8096\n"
     ]
    }
   ],
   "source": [
    "# calculate samples per epoch so that epoch can consist of integer number of batches\n",
    "VAL_SAMPLES_PER_EPOCH = int(len(X_files_val) / VAL_BATCH_SIZE) * VAL_BATCH_SIZE\n",
    "print ('Samples per epoch (val):', VAL_SAMPLES_PER_EPOCH, 'of', len(X_files_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "\n",
    "def create_model():\n",
    "\n",
    "    image_input = Input(shape=IMAGE_SHAPE, name='image_input')\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(image_input)\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    features = Dropout(rate=0.5)(x)\n",
    "\n",
    "    out_tags_misc = Dense(\n",
    "        Y_tags_misc.shape[1], activation='sigmoid', name='tags_misc')(features)\n",
    "    out_tags_weather = Dense(\n",
    "        Y_tags_weather.shape[1], activation='softmax',\n",
    "        name='tags_weather')(features)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[image_input], outputs=[out_tags_misc, out_tags_weather])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adadelta',\n",
    "        loss={\n",
    "            'tags_misc': 'binary_crossentropy',\n",
    "            'tags_weather': 'binary_crossentropy'\n",
    "        },\n",
    "        loss_weights={'tags_misc': 1.,\n",
    "                      'tags_weather': 0.333})\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_transform_batch(b):\n",
    "    for i, img in enumerate(b[0]):\n",
    "        b[0][i] = random_transform(img, debug=False)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data generation\n",
    "\n",
    "\n",
    "def train_generator():\n",
    "\n",
    "    while True:\n",
    "\n",
    "        train_batch_index = np.random.randint(\n",
    "            TRAIN_SAMPLES_PER_EPOCH / TRAIN_BATCH_SIZE)\n",
    "\n",
    "        b = generate_batch(\n",
    "            n_samples=TRAIN_BATCH_SIZE,\n",
    "            batch_index=train_batch_index,\n",
    "            X_files=X_files_train,\n",
    "            Y_tags_misc=Y_tags_misc_train,\n",
    "            Y_tags_weather=Y_tags_weather_train,\n",
    "            images_dir=IMAGES_DIR,\n",
    "            image_shape=IMAGE_SHAPE)\n",
    "\n",
    "        b = random_transform_batch(b)\n",
    "\n",
    "        yield b\n",
    "\n",
    "\n",
    "def val_generator():\n",
    "    while True:\n",
    "        val_batch_index = np.random.randint(\n",
    "            VAL_SAMPLES_PER_EPOCH / VAL_BATCH_SIZE)\n",
    "\n",
    "        b = generate_batch(\n",
    "            n_samples=VAL_BATCH_SIZE,\n",
    "            batch_index=val_batch_index,\n",
    "            X_files=X_files_val,\n",
    "            Y_tags_misc=Y_tags_misc_val,\n",
    "            Y_tags_weather=Y_tags_weather_val,\n",
    "            images_dir=IMAGES_DIR,\n",
    "            image_shape=IMAGE_SHAPE)\n",
    "\n",
    "        yield b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=32376, validation_steps=8096, initial_epoch=0, callbacks=[<keras.ca..., class_weight=None, verbose=1, validation_data=<generator..., workers=4, max_queue_size=40, use_multiprocessing=True, epochs=1)`\n",
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:1786: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32375/32376 [============================>.] - ETA: 0s - loss: 0.1873 - tags_misc_loss: 0.1407 - tags_weather_loss: 0.1399"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:1937: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_tags_weather_loss': 0.112647494308102, 'val_tags_misc_loss': 0.12317933918486751, 'tags_misc_loss': 0.14074548956566463, 'val_loss': 0.16069095540357378, 'loss': 0.18732768220379156, 'tags_weather_loss': 0.13988646256981827}\n",
      "32376/32376 [==============================] - 286s - loss: 0.1873 - tags_misc_loss: 0.1407 - tags_weather_loss: 0.1399 - val_loss: 0.1607 - val_tags_misc_loss: 0.1232 - val_tags_weather_loss: 0.1126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6413e4f828>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator(),\n",
    "    steps_per_epoch=TRAIN_SAMPLES_PER_EPOCH,\n",
    "    epochs=TRAIN_EPOCHS,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        TensorBoard(log_dir=TENSORBOARD_DIR, histogram_freq=0),\n",
    "        ModelCheckpoint(\n",
    "                MODEL_CHECKPOINT_DIR + \\\n",
    "                '/e{epoch:02d}-l={loss:.5f}-vl={val_loss:.5f}.h5',\n",
    "                monitor='val_loss', verbose=0, save_best_only=False,\n",
    "                save_weights_only=False, mode='auto'\n",
    "            ),\n",
    "        MyCallback()\n",
    "    ],\n",
    "    validation_data=val_generator(),\n",
    "    validation_steps=VAL_SAMPLES_PER_EPOCH,\n",
    "    class_weight=None,\n",
    "    max_q_size=40,\n",
    "    workers=4,\n",
    "    pickle_safe=True,\n",
    "    initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999/1012 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "preds = model.predict_generator(val_generator(), steps=VAL_SAMPLES_PER_EPOCH/VAL_BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tags = preds[0]; p_weather = preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.hstack((p_tags, p_weather))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.hstack((Y_tags_misc_val, Y_tags_weather_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61798881319456889"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(t, p > 0.01, beta=2, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
